{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to HCBC Platform","text":"<p>Welcome to our Platform guidelines web-page. Here analysts and developers will find guidelines on how to work with our most common environments.</p> <p>We are developing platforms for each analysis type we have experience with at HCBC.</p> <p>Most analyses will follow the similar trajectory for set-up. We will note where the trajectories diverge with tables where you will select the appropriate analysis.</p>"},{"location":"#set-up-the-package","title":"Set up the package","text":"O2 instructions- Click to expand!  Log onto O2 via the command line and check two things (first-time only):      * Remove `bcbio` from you `PATH` by commenting the line in your `.bashrc` if you have it    * Remove any path you load using the R env variables that could be in your `.Rprofile` or `.bashrc`  Go to the [O2 Portal](https://o2portal.rc.hms.harvard.edu/) and select `HMS-RC Application`, then `RStudio Environment`   Start Rstudio with using your desired partition, memory, core and time directives. Add these modules to \"Modules to be loaded\":   <pre><code>git/2.9.5  gcc/9.2.0 imageMagick/7.1.0 geos/3.10.2 cmake/3.22.2 R/4.3.1 fftw/3.3.10 gdal/3.1.4 udunits/2.2.28  boost/1.75.0\n</code></pre>    Click \"Launch\"    Open RStudio by clicking on the \"Connect to RStudio Server\"    When the session is started, set your library path by typing this command in your console Rstudio window in order to be able to load `bcbioR`:  <pre><code>.libPaths(\"/n/app/bcbio/R4.3.1\")\n</code></pre>  Next, load <code>bcbioR</code> with: <pre><code>library(bcbioR)\n</code></pre> <p>Check the package version of <code>bcbioR</code> using:</p> <pre><code>packageVersion(\"bcbioR\")\n</code></pre> <p>Make sure the version is 0.4.* or later.</p> <p></p> <p>Note: If you are working in your local environment, install <code>bcbioR</code> with <pre><code>devtools::install_github(\"bcbio/bcbioR\",build_manual = TRUE, build_vignettes = TRUE)\n</code></pre></p>"},{"location":"#general-project","title":"General Project","text":"<p>Use the app in the dropdown below to use the HBC app to set up a project's name. This name will be used for O2, FAS, GitHub and Dropbox. This name is likely already defined in the Trello card.</p> Click here to use the HBC app for naming a project <p></p> <p>This set up needs bcbioR and usethis packages. If you are working on the O2 Portal <code>usethis</code> is within <code>/n/app/bcbio/R4.3.1</code>, so you will not need to install it. Also, <code>usethis</code> is a dependency of <code>bcbioR</code>, so if you are working locally it should have come along with the download of <code>bcbioR</code>.</p>"},{"location":"#create-the-rstudio-project","title":"Create the Rstudio project","text":"<p>Assign the path that you will be using as the path for your project to the object <code>project_path</code> into the <code>/n/data1/cores/bcbio/PIs</code> space on O2:</p> <pre><code>project_path &lt;- \"/n/data1/cores/bcbio/PIs/PI_name/lastname_postdoc_rnaseq_human_heart_hbc00000\"\n</code></pre> <p>Now, we will need to create a directory using this path to put our analysis in. If this directory already exists, then you can skip this step. The directory creation can be done with this command:</p> <pre><code>dir.create(project_path)\n</code></pre> <p>Now, we can open an Rproject for our analysis in this path using:</p> <pre><code>usethis::proj_activate(project_path)\n</code></pre> <p>Note: This will restart the session in the project directory. This restart will clear the <code>.libPaths(\"/n/app/bcbio/R4.3.1\")</code> and <code>library(bcbioR)</code> that we used earlier, so we will need to re-do them in the following steps. </p>"},{"location":"#using-the-template-reports","title":"Using the template reports","text":"<p>Many analyses have template reports that you can use. You can use these by using the approriate <code>bcbioR::bcbio_templates()</code> command from the table below:</p> Type of Analysis <code>bcbioR::bcbio_templates()</code> command Bulk RNA-seq  <code>bcbioR::bcbio_templates(type=\"rnaseq\", outpath=\"reports\")</code> Single-cell RNA-seq  <code>bcbioR::bcbio_templates(type=\"singlecell\", outpath=\"reports\")</code> ChIP-Seq  <code>bcbioR::bcbio_templates(type=\"chipseq\", outpath=\"reports\")</code> CellChat  Under development: <code>bcbioR::bcbio_templates(type=\"singlecell_delux\", outpath=\"reports\")</code> COSMX  <code>bcbioR::bcbio_templates(type=\"spatial\", outpath=\"reports\")</code> DNA Methylation Under development"},{"location":"#setting-up-your-workspace-in-o2","title":"Setting up your workspace in O2","text":"<p>We will now add the <code>.libPath()</code> that is appropriate for our type of analysis. You can use the table below to determine which <code>.libPath()</code> is appropriate for your analysis:</p> Type of Analysis <code>.libPath()</code> command Bulk RNA-seq <code>.libPaths(\"/n/app/bcbio/R4.3.1_rnaseq\")</code> Single-cell RNA-seq <code>.libPaths(\"/n/app/bcbio/R4.3.1_singlecell\")</code> ChIP-Seq <code>.libPaths(\"/n/app/bcbio/R4.3.1_chipseq\")</code> CellChat <code>.libPaths(\"/n/app/bcbio/R4.3.1_cellchat\")</code> DNA Methylation <code>.libPaths(\"/n/app/bcbio/R4.3.1_methylation\")</code> <p>Since our loaded libraries were wiped when we created a new project, we will need to reload <code>bcbioR</code>:</p> <pre><code>library(bcbioR)\n</code></pre> <p>Once again, let's just double check our version of <code>bcbioR</code> to make sure we are using version 0.4. or later.</p> <pre><code>packageVersion(\"bcbioR\")\n</code></pre> <p>Next, we need to set the library that <code>bcbioR</code> will use each time you open up this RStudio project. By using the <code>bcbioR::use_library()</code>, you will be adding the path to your project <code>.Rprofile</code> and this will be sourced each time when you open this RStudio project.</p> Type of Analysis <code>bcbioR::use_library()</code> command Bulk RNA-seq <code>bcbioR::use_library(\"/n/app/bcbio/R4.3.1_rnaseq\")</code> Single-cell RNA-seq <code>bcbioR::use_library(\"/n/app/bcbio/R4.3.1_singlecell\")</code> ChIP-Seq <code>bcbioR::use_library(\"/n/app/bcbio/R4.3.1_chipseq\")</code> CellChat <code>bcbioR::use_library(\"/n/app/bcbio/R4.3.1_cellchat\")</code> DNA Methylation <code>bcbioR::use_library(\"/n/app/bcbio/R4.3.1_methylation\")</code> <p>Now, we will use <code>bcbioR</code> to set-up the directory structure that we will be using for our analysis using the following command:</p> <pre><code>bcbioR::bcbio_templates(type=\"base\", outpath=\".\", org=\"hcbc\")\n</code></pre>"},{"location":"#setting-up-github-and-rstudio","title":"Setting up GitHub and RStudio","text":"<p>Now, we will connect O2 with GitHub. First, check in your Home directory if a <code>.gitconfig</code> file exists. You should only need to do this once. The contents should look like:</p> <pre><code>[credential]\n    helper = store\n[user]\n    email = your_email@gmail.com\n    name = your_GitHub_username\n</code></pre> <p>Where <code>your_email@gmail.com</code> is the e-mail associated with your GitHub account and <code>your_GitHub_username</code> is your GitHub username.</p> <p>If you do not have a <code>.gitconfig</code> file in your Home directory, follow the instructions in the dropdown below to create a <code>.gitconfig</code> file. </p> Click here for instructions for making a <code>.gitconfig</code> file In order to make a <code>.gitconfig</code>, you will need to run the following command: <pre>\nusethis::use_git_config(user.name = \"your_GitHub_username\", user.email = \"your_email@gmail.com\")\n</pre> You will replace <code>your_GitHub_username</code> with your GitHub username and <code>your_email@gmail.com</code> with the e-mail associated with your GitHub account.  Reminder: If you already have your GitHub username and e-mail associated with your GitHub account in your `.gitconfig` file then you can skip this step.  Click on circular arrow in the top right of the <code>Files</code> tab called <code>Refresh file listing</code>. You can check that you have successfully made this <code>.gitconfig</code> file by looking for the hidden file in your home directory. The content should look like: <pre>\n[credential]\n    helper = store\n[user]\n    email = your_email@gmail.com\n    name = your_GitHub_username\n</pre>  Note: In order to see hidden file in your file browser on the O2 Portal, you will need to click on the cog in the top right of the <code>Files</code> tab and select <code>Show Hidden Files</code>."},{"location":"#getting-the-git-tab","title":"Getting the Git tab","text":"<p>Now, we would like to get the Git tab into our Workspace Browser (where <code>Environment</code>, <code>History</code>, <code>Connections</code> and <code>Tutorial</code> tabs are located). We show this transition below:</p> <p></p> <p>In order to do this we will use the following command:</p> <pre><code>usethis::use_git()\n</code></pre> <p>This command is the command one would usually use in order to make a commit. However, if we choose to not make a commit and then restart R, it will give us our Git tab in the Workspace Browser. This command should return:</p> <pre><code>\u2714 Setting active project to \"/home/wig051/git_demo\".\n\u2714 Initialising Git repo.\n\u2714 Adding \".Rdata\", \".httr-oauth\", \".DS_Store\", and \".quarto\" to .gitignore.\n\u2139 There are 6 uncommitted files:\n\u2022 .gitignore\n\u2022 .Rprofile\n\u2022 DataManagement-Checklist.pdf\n\u2022 information.R\n\u2022 README.md\n\u2022 reports/\n! Is it ok to commit them?\n\n1: Yes\n2: Negative\n3: Not now\n</code></pre> <p>We do not want to commit these files yet, so select one of the answers like <code>Negative</code>, <code>No way</code> or <code>No</code>.</p> <p>Note: It is unclear why Git gives us three choices. The possible choices are re-arranged each time and have different text. So your option may vary a bit from these, select one of the appropriate options for NOT commiting.</p> <p>Next, you will be prompted as to whether you want to restart R:</p> <pre><code>A restart of RStudio is required to activate the Git pane.\nRestart now?\n\n1: For sure\n2: Negative\n3: Not now\n</code></pre> <p>We will need to restart R in order to get the Git tab in our R Studio, so select <code>For sure</code>, <code>Yeah</code> or some other option for answering in the affirmative. </p>"},{"location":"#creating-the-first-commit","title":"Creating the first commit","text":"<p>Now, we are going to create our first commit. In order to do this, we need to:</p> <ol> <li>Navigate to the Git tab in our Workspace Browser</li> <li>Left-click to check the \"Staged\" checkboxes next to <code>README.md</code> and <code>.gitignore</code> to select the files that we would like to add to our first commit</li> <li>Left-click Commit in the Git tab</li> <li>Add a message for our commit</li> <li>Left-click Commit underneath the textbox where we added the message for our commit</li> <li>Close both Git windows</li> </ol> <p>These steps are summarized in the GIF below:</p> <p></p>"},{"location":"#pushing-our-initial-commit","title":"Pushing our initial commit","text":"<p>Now we will use the function to push these changes to GitHub with the following command:</p> <pre><code>usethis::use_github(org=\"hbc\", private=TRUE)\n</code></pre> <p>If you do not have a valid GitHub token, this will give you an error (see below). If you already have a valid GitHub token, you will get this text in your console and it will push this repository to the HBC GitHub with the following output:</p> <pre><code>\u2139 Defaulting to \"https\" Git protocol.\n\u2714 Setting active project to \"/home/wig051/git_demo\".\n\u2714 Creating private GitHub repository \"hbc/git_demo\".\n\u2714 Setting remote \"origin\" to \"https://github.com/hbc/git_demo.git\".\n\u2714 Pushing \"master\" branch to GitHub and setting \"origin/master\" as upstream branch.\n\u2714 Opening URL &lt;https://github.com/hbc/git_demo&gt;.\n</code></pre> <p>If the push is successful, then it will look like this GIF below:</p> <p></p> <p>Note: You might get a GitHub 404 error page (see image below) when you do your first push to GitHub. Just refresh the page in your browser and it should be resolve itself. <p></p></p>"},{"location":"#expired-or-non-existent-github-token","title":"Expired or non-existent GitHub token","text":"<p>However, if your token is expired or this is your first time using GitHub from O2, then you will get this message:</p> <pre><code>\u2139 Defaulting to \"https\" Git protocol.\n\u2714 Setting active project to \"/home/wig051/git_demo\".\nError in `usethis::use_github()`:\n\u2716 Unable to discover a GitHub personal access token.\n\u2139 A token is required in order to create and push to a new repo.\n\u2610 Call usethis::gh_token_help() for help configuring a token.\nRun `rlang::last_trace()` to see where the error occurred.\n</code></pre> <p>If this is the case, then you will need to create a new GitHub token, click on the dropdown box below for instructions on how to create a new GitHub token.</p> Click here to see how to create a GitHub Token The first thing we will need to do when setting up our GitHub token is to set-up our credential helper. We can do this by left-clicking on the <code>Terminal</code> table in the Console Window. You may need to load Git in the Terminal using: <pre>\nmodule load git\n</pre> Then you can provide the following line of code to store your GitHub token for future O2 sessions: <pre>\ngit config --global credential.helper store\n</pre> This process is summarized in the GIF below: <p></p> Now that we have let Git know to store our GitHub token, we can create one. In order to create a GitHub token, you will need to run: <pre>\nusethis::create_github_token()\n</pre> This will take you to a GitHub Webpage. It may prompt you to sign-in to GitHub. From here, you need to name your token and select an expiration date for your token. Then, scroll to the bottom of the page and left-click Generate token. These step are summarized in the GIF below: <p></p> Next, you will want to copy your GitHub Token and go back to RStudio. We need to set our credentials by using the command: <pre>\ngitcreds::gitcreds_set()\n</pre> Paste in your copied GitHub token and hit Return/Enter. It should return: <pre>\n-&gt; Adding new credentials...\n-&gt; Removing credentials from cache...\n-&gt; Done.\n</pre> These steps are summarized in the GIF below: <p></p> Now you should have a hidden file called <code>.git-credentials</code> in your Home directory and it should look like: <pre>\nhttps://PersonalAccessToken:YOUR_GITHUB_TOKEN@github.com\n</pre> Where <code>YOUR_GITHUB_TOKEN</code> has been replaced with your GitHub Token.  Note: In order to see hidden file in your file browser on the O2 Portal, you will need to click on the cog in the top right of the <code>Files</code> tab and select <code>Show Hidden Files</code>.  Next, try pushing your repository to the HBC GitHub again with: <pre>\nusethis::use_github(org=\"hbc\",private=TRUE)\n</pre>"},{"location":"#making-your-first-edit","title":"Making your first edit","text":"<p>We will now make an edit and push that to GitHub. </p>"},{"location":"#editing-the-readmemd","title":"Editing the <code>README.md</code>","text":"<p>We are going to edit the <code>README.MD</code> using these steps:</p> <ol> <li>Open the <code>README.md</code></li> <li>Change the header from <code>Guidelines</code> to the assigned HBC code for the project (<code>PI_brief_description_hbcXXXX</code>)</li> <li>Save the changes to <code>README.md</code></li> <li>Select the checkbox in the \"Staged\" area of the Git tab for the <code>README.md</code></li> <li>Left-click Commit</li> <li>Add a commit description</li> <li>Left-click commit again</li> <li>Left-click Close to close the pop-up window for the commit</li> </ol> <p>These steps are summarized in the GIF below:</p> <p></p> <p></p>"},{"location":"#pushing-the-edit-to-github","title":"Pushing the edit to GitHub","text":"<p>Now that we have made this commit, we will push it to GitHub using these steps:</p> <ol> <li>After completing your commit, left-click Push</li> <li>Left-click Close to close the pop-up window for the push</li> <li>Close the additional pop-up window</li> <li>Navigate to the GitHub page for this repository</li> <li>Refresh the page if necessary</li> </ol> <p>You should now see the HBC code as the header to the <code>README.md</code> on GitHub. These steps are summarized in the GIF below:</p> <p></p> <p></p>"},{"location":"#tips-for-moving-forward","title":"Tips for Moving Forward","text":"<p>Now that we've gotten set-up for our project, here are a few last tips to try to make your experience smooth:</p> <ul> <li>You are welcome to selectively commit and push the parts of these template reports that you would like to have on GitHub.</li> <li>Try to avoid editing files directly on GitHub. If you do, it will be important that you <code>Pull</code> the repository onto O2 before continuing on with your work on O2. If you forget to do this pull and make commits on O2, you can fix it, but it is beyond the scope of this guide.</li> <li>Use the checklist in the <code>README.md</code> to help keep track of your progress.</li> </ul>"},{"location":"#note","title":"Note","text":"<p>These materials have been developed by members of the teaching and platform team at the Harvard Chan Bioinformatics Core (HBC) RRID:SCR_025373. </p>"},{"location":"devops/","title":"Build platforms","text":"<p>Content </p>"},{"location":"devops/#app-development","title":"App development","text":"<ul> <li>Use HBC or bcbio organization</li> <li>Private repo prior to release</li> <li>Test data needs to be part of the code</li> <li>README to explain how to use the test data</li> <li>First release should be prior to client<ul> <li>Must be usable at First release</li> <li>At least one other person to review and approve </li> <li>After that main branch get blocked and version numbers start at 1.0.0</li> <li>Then start dev branch</li> </ul> </li> <li>Each time we merge a Pull request, we need to make a release</li> <li>Publish on Posit connect with a new name that matches the version</li> </ul>"},{"location":"devops/#configure-to-use-posit-package-manager","title":"Configure to use posit package manager","text":"<p>source</p> <pre><code># Configure BioCManager to use Posit Package Manager:\noptions(BioC_mirror = \"https://packagemanager.posit.co/bioconductor\")\noptions(BIOCONDUCTOR_CONFIG_FILE = \"https://packagemanager.posit.co/bioconductor/config.yaml\")\n\n# Configure a CRAN snapshot compatible with Bioconductor 3.18:\noptions(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2024-05-01\"))\n</code></pre>"},{"location":"devops/#creating-env-in-data-studio","title":"Creating env in Data Studio","text":"<p>Set up the package manager properly:</p> <pre><code># Configure BioCManager to use Posit Package Manager:\noptions(BioC_mirror = \"https://packagemanager.posit.co/bioconductor/latest\")\noptions(BIOCONDUCTOR_CONFIG_FILE = \"https://packagemanager.posit.co/bioconductor/latest/config.yaml\")\n\n# Configure a CRAN snapshot compatible with Bioconductor 3.20:\noptions(repos = c(CRAN = \"https://packagemanager.posit.co/cran/__linux__/jammy/latest\"))\ninstall.packages(\"BiocManager\")\n</code></pre> <p>Install minimum system library packages from ubuntu22.</p> <p>Install all needed packages, and stop the server to get the first checkpoint with the packages installed. </p> <p>After this, other users can start a new DataStudio from it with the dependencies already installed.</p>"},{"location":"devops/#installing-sc-packages-in-o2","title":"Installing sc packages in O2","text":""},{"location":"devops/#cellchat","title":"CELLCHAT","text":"<p>Use these modules when starting Rstudio in O2:</p> <pre><code>gcc/9.2.0 imageMagick/7.1.0 geos/3.10.2 cmake/3.22.2 R/4.3.1 fftw/3.3.10 gdal/3.1.4 udunits/2.2.28  boost/1.75.0 python/3.9.14\n</code></pre> <p>In the R console you can load deps with these lines:</p> <pre><code># To use it\nreticulate::use_virtualenv(\"/n/app/bcbio/R4.3.1_python_cellchat\")\nreticulate::py_config() # check it is pointing to right versions: umap-learn 0.5.5 and umap 1.26\nSys.getenv(\"PYTHONPATH\") # needs to be empty\n\npy_module_available(module = 'umap')\nreticulate::import(module = \"umap\", delay_load = TRUE)\n.libPath(\"/n/app/bcbio/R4.3.1_cellchat\")\nlibrary(CellChat)\n</code></pre> <p>To install it:</p> <pre><code># To install python deps\nvirtualenv_install(\"/n/app/bcbio/R4.3.1_python_cellchat\", packages=\"umap-learn==0.5.5\",python_version=\"3.9\",force=TRUE)\nvirtualenv_install(\"/n/app/bcbio/R4.3.1_python_cellchat\", packages=\"numpy==1.26\",python_version=\"3.9\")\n#.rs.restartR() # restart R manually if outside RStudio\nreticulate::py_config() # check it is pointing to right versions: umap-learn 0.5.5 and umap 1.26\nSys.getenv(\"PYTHONPATH\") # needs to be empty\n\n# R package\nBiocManager::install(\"BiocNeighbors\")\ninstall.packages('NMF')\ninstall.packages(\"circlize\")\ndevtools::install_github(\"jinworks/CellChat\")\n</code></pre>"},{"location":"devops/#build-environments","title":"Build environments","text":""},{"location":"devops/#scgpt-in-fas","title":"scGPT in FAS","text":"<pre><code>conda create -p ./scgpt-2 python=3.9 pip ipykernel   -c conda-forge\nconda install ipywidgets -c conda-forge\npip install torch==2.1.2\nconda install numpy\npip install scgpt\nconda install wandb -c conda-forge\npython -m ipykernel install --prefix=/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/scgpt-2 --name 'dcgpt2' --display-name 'scgpt-2'\n</code></pre>"},{"location":"environments/","title":"Environments availables","text":""},{"location":"environments/#scgpt","title":"scGPT","text":"<p>Only available at FAS computing resources.</p> <p>Please, reach out to platform to access for the first time to this env:</p> <ul> <li> <p>Add the environment first:</p> <ul> <li>Only the first time, add the env to the notebook kernels:<ul> <li><code>echo \"n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/scgpt-2\" &gt;&gt; ~/.conda/environments.txt</code></li> </ul> </li> </ul> </li> <li> <p>Start a python notebook on the ondemand web-page. </p> <ul> <li>You need to be connected to the VPN to be connected. </li> <li>Use <code>gpu</code> partition and if you need more than one GPU or <code>gpu_test</code> if you need something that won't take a long time <ul> <li>add these to the sbatch options <code>--gres=gpu:n</code> in the advance options, they are below in the page.</li> </ul> </li> <li>Add <code>gcc/13.2.0-fasrc01</code> to the list of modules to load</li> </ul> </li> <li>Once connected, if you get asked to use a password, just close the windows and open again.<ul> <li>If you didn't add module <code>gcc/13.2.0-fasrc01</code>, do this now:<ul> <li>Initiate a terminal session</li> <li><code>module load gcc/13.2.0-fasrc01</code></li> </ul> </li> <li>Then, start a notebook choosing as kernel <code>scgpt-2</code></li> </ul> </li> <li>Validate everything works with these commands in the python notebook<ul> <li><code>import torch</code></li> <li><code>torch.cuda.is_available()</code> -&gt; Should return <code>True</code></li> <li><code>torch.cuda.device_count()</code> -&gt; Should return `</li> <li><code>import scgpt</code></li> </ul> </li> </ul>"},{"location":"pipelines/","title":"Introduction to HCBC pipelines","text":"<p>Content - </p>"},{"location":"pipelines/#data-management","title":"Data Management","text":""},{"location":"pipelines/#aws","title":"AWS","text":"<ul> <li>Samplesheet input files for pipelines<ul> <li><code>pipelineName_PI_hbcNNNNNN</code></li> <li>Have a copy in project folder in O2</li> <li>Manually removing weekly during platform meeting</li> </ul> </li> <li>Raw data is under <code>input</code> folder <ul> <li>See instructions below to move data in/out</li> <li><code>pipelineName_PI_hbcNNNNNN</code></li> <li>lifecycle 14 days</li> </ul> </li> <li>Pipeline outputs are under <code>results</code>:<ul> <li><code>pipelineName_PI_hbcNNNNNN</code></li> <li>lifecycle 14 days for bigger than 1gb</li> <li>Move output pipeline to project folder under <code>final</code> folder</li> </ul> </li> </ul>"},{"location":"pipelines/#move-data-inout-of-aws","title":"Move data in/out of AWS","text":"<p>Follow this to copy data in and out of our AWS space:</p> <ul> <li>Log in into transfer node in O2</li> <li>Type <code>sudo -su bcbio</code> to be bcbio user</li> <li>Use this command to copy data to AWS: <pre><code>/usr/local/bin/aws s3 sync $FOLDER_WITH_FASTQ s3://hcbc-seqera/input/rnaseq_piname_hbcNNNN\n</code></pre></li> <li>Use this command to copy data from AWS: <pre><code>/usr/local/bin/aws s3 sync s3://hcbc-seqera/results/rnaseq_piname_hbcNNNN $FOLDER_PROJECT\n</code></pre> Make sure bcbio group has read/write access to the folders otherwise <code>aws</code> command won't work, but won't error either.</li> </ul>"},{"location":"pipelines/#parameters","title":"Parameters","text":""},{"location":"pipelines/#rnaseq","title":"RNAseq","text":"<ul> <li>We use salmon with bam files produced by STAR mapped to transcriptome for quantification</li> </ul>"},{"location":"pipelines/#chipseq","title":"CHIPseq","text":"<ul> <li>It can analyze multiple antibodies in one pipeline run (pipeline splits samples by antibody)</li> <li>Default parameters</li> <li>de-duplication for all samples</li> <li><code>bowtie</code> is set up with these extra parameters: <code>--sensitive-local -X 1000</code> (this is only true in seqera dev environment, not production)</li> <li><code>macs_gsize</code> needs to be setup for each species accordingly tools</li> </ul>"},{"location":"pipelines/#cutrun","title":"CUT&amp;RUN","text":"<ul> <li>Run once per antibody (because pipeline does not split samples by antibody)</li> <li>Turn on <code>dedup_target_reads</code></li> <li>Use both <code>macs2</code> and <code>seacr</code> for peakcalling (list macs2 first so it is used as primary)</li> <li>Normalization mode is set to <code>CPM</code> (can be changed if client has spike-in samples)</li> <li>Depending on the number of samples, user may want to skip <code>deeptools</code> processes involving all samples</li> <li>processes including SAMTOOLS_SORT, BEDTOOLS_SORT, SAMTOOLS_CUSTOMVIEW, FRAG_LEN_HIST, and DEEPTOOLS_PLOTHEATMAP_GENE_ALL are given more memory than nf-core default</li> </ul>"},{"location":"pipelines/#atacseq","title":"ATACseq","text":"<p>All peaks <code>nf-core-atac-seq_shift</code>: - shift is on - keep_dup is false</p> <p>NFR peaks <code>nf-core-atac-seq_shift_NFR</code>: - same than previous except parameters for Aligmentsieve:   - <code>--minFragmentLength 0</code>   - <code>--maxFragmentLength 120</code></p> <p>Note: Recommendation to check the fragment length distribution after the run to make sure you're capturing the NFRs. Note: We don't need the MN(180, 247), DN (315, 473) and TN (558, 615), unless it's a specific case where we are looking at global shifts in accessibility</p>"},{"location":"pipelines/#nextflow-in-seqera-platform","title":"Nextflow in Seqera platform","text":"<ul> <li>Create an user here: https://cloud.seqera.io/login</li> <li>Ask Platform team to add you to HCBC workspace</li> <li>Transfer data to HCBC S3: Ask Alex/Lorena. Files will be at our S3 bucket <code>input/pipelineName_PI_hbcNNNNNN</code> folder</li> </ul>"},{"location":"pipelines/#rnaseq_1","title":"RNAseq","text":"<ul> <li>Prepare the CSV file according this instructions. File should look like this:</li> </ul> <pre><code>sample,fastq_1,fastq_2,strandedness\nCONTROL_REP1,s3path/AEG588A1_S1_L002_R1_001.fastq.gz,s3path/AEG588A1_S1_L002_R2_001.fastq.gz,auto\nCONTROL_REP1,s3path/AEG588A1_S1_L003_R1_001.fastq.gz,s3path/AEG588A1_S1_L003_R2_001.fastq.gz,auto\nCONTROL_REP1,s3path/AEG588A1_S1_L004_R1_001.fastq.gz,s3path/AEG588A1_S1_L004_R2_001.fastq.gz,auto\n</code></pre> <p>Use <code>bcbio_nfcore_check(csv_file)</code> to check the file is correct.</p> <p>You can add more columns to this file with more metadata, and use this file as the <code>coldata</code> file in the templates.</p> <ul> <li>Safe the file under <code>meta</code> folder</li> <li>Upload this file to our <code>Datasets</code> in Seqera using the name of the project but starting with <code>pipelineName_PI_hbcNNNNNN</code></li> <li>Go to <code>Launchpad</code>, select <code>nf-core_rnaseq</code> pipeline, and select the previous created <code>Datasets</code> in the <code>input</code> parameter after clicking in <code>Browser</code></li> <li>Select an output directory with the same name used for the <code>Dataset</code> inside the <code>results/pipelineName_PI_hbcNNNNNN</code> folder in S3</li> <li>When pipeline is done, data will be copied to our on-premise HPC in the scratch system under <code>scratch/groups/hsph/hbc/bcbio/</code> folder</li> </ul>"},{"location":"pipelines/#nextflow-in-o2","title":"Nextflow in O2","text":"<ul> <li>Nextflow is available at <code>/n/app/bcbio/nextflow/nextflow</code>. </li> <li>Singularity containers at available at <code>/n/app/singularity/containers/shared/bcbio/</code>.</li> <li>Cluster config: <code>/n/app/bcbio/nextflow/o2.config</code></li> </ul> <p>An example of sbatch script is:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=Nextflow      # Job name\n#SBATCH --partition=priority            # Partition name\n#SBATCH --time=1-23:59                 # Runtime in D-HH:MM format\n#SBATCH --nodes=1                      # Number of nodes (keep at 1)\n#SBATCH --ntasks=1                     # Number of tasks per node (keep at 1)\n#SBATCH --cpus-per-task=1            # CPU cores requested per task (change for threaded jobs)\n#SBATCH --mem=12G                     # Memory needed per node (total)\n#SBATCH --error=jobid_%j.err           # File to which STDERR will be written, including job ID\n#SBATCH --output=jobid_%j.out          # File to which STDOUT will be written, including job ID\n#SBATCH --mail-type=ALL                # Type of email notification (BEGIN, END, FAIL, ALL)\n\nmodule load java/jdk-21.0.2\nexport NXF_APPTAINER_CACHEDIR=/n/app/singularity/containers/shared/bcbio/nf-core-rnaseq-3.14.0\nexport NXF_SINGULARITY_LIBRARYDIR=/n/app/singularity/containers/shared/bcbio/nf-core-rnaseq-3.14.0\n\n/n/app/bcbio/nextflow/nextflow run nf-core/rnaseq -r 3.14.0 -profile singularity \\\n    -c /n/app/bcbio/nextflow/o2.config -c /n/app/bcbio/nextflow/rnaseq.resources.config \\\n    -params-file /n/app/bcbio/nextflow/rnaseq.json \\\n    --input samplesheet.csv --outdir this_folder -resume\n</code></pre>"},{"location":"pipelines/#rnaseq_2","title":"RNAseq","text":"<p>Containers at <code>/n/app/singularity/containers/shared/bcbio/nf-core-rnaseq-3.14.0</code></p>"},{"location":"pipelines/#viralrecon","title":"viralrecon","text":"<p>Read documentation here. </p> <p>This is an example for test data:</p> <p><pre><code>module load java/jdk-21.0.2\nexport NXF_APPTAINER_CACHEDIR=/n/app/singularity/containers/shared/bcbio/nf-core-viralrecon_2.6.0\nexport NXF_SINGULARITY_LIBRARYDIR=/n/app/singularity/containers/shared/bcbio/nf-core-viralrecon_2.6.0\n\n/n/app/bcbio/nextflow/nextflow run nf-core/viralrecon -r 2.6.0 -profile singularity,test --outdir this_folder -resume\n</code></pre> To run your data, prepare input file following this doc, and run it like this:</p> <pre><code>/n/app/bcbio/nextflow/nextflow run nf-core/viralrecon -r 2.6.0 -profile singularity --outdir this_folder --input samplesheet.csv -resume\n</code></pre>"},{"location":"pipelines/#nextflow-in-fas","title":"Nextflow in FAS","text":"<p>We use FAS to run pipelines in scratch, main storage location for data is still O2. </p> <ul> <li>Run pipelines in scratch: <code>/n/netscratch/hsph_bioinfo/Lab</code></li> <li>Keep downstream analysis in PIs folder: <code>/n/holylfs05/LABS/hsph_bioinfo/Lab/PIs</code></li> </ul> <p>Pipelines that have been run so far in FAS: - rnaseq - scrnaseq - cutandrun</p> <p>Before using nextflow, you need to load a recent version of java:</p> <pre><code>module load jdk/21.0.2-fasrc01\n</code></pre> <p>Use nextflow at <code>/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/nextflow</code></p> <p>Use config file at <code>/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/cannon.config</code></p> <p>Example command to run in an interactive job: Note that this is only for test datasets requiring minimal CPUs, memory, and parallelization. Otherwise, submit as sbatch.  <pre><code>/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/nextflow run nf-core/rnaseq -profile test,singularity --outdir tmp -c /n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/fas.config\n</code></pre></p> <p>For non-test data, you will use sbatch to submit the head job of the pipeline, which will in turn submit the child jobs.  Modify this template as needed before using it:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=Nextflow      # Job name\n#SBATCH --partition=shared            # Partition name\n#SBATCH --time=0-48:59                 # Runtime in D-HH:MM format\n#SBATCH --nodes=1                      # Number of nodes (keep at 1)\n#SBATCH --ntasks=1                     # Number of tasks per node (keep at 1)\n#SBATCH --mem=16G                     # Memory needed per node (total)\n#SBATCH --error=jobid_%j.err           # File to which STDERR will be written, including job ID\n#SBATCH --output=jobid_%j.out          # File to which STDOUT will be written, including job ID\n#SBATCH --mail-type=ALL                # Type of email notification (BEGIN, END, FAIL, ALL)\n\nmodule load jdk/21.0.2-fasrc01\n\n# modify these paths as necessary to point to the containers for the pipeline you're using\nexport NXF_APPTAINER_CACHEDIR=/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/nfcore-rnaseq\nexport NXF_SINGULARITY_LIBRARYDIR=/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/nfcore-rnaseq\n\n# Optional: if you'd like to monitor your run in Seqera Platform, set up a token there and use it here\nexport TOWER_WORKSPACE_ID=268530979103043\nexport TOWER_ACCESS_TOKEN=&lt;your_access_token&gt;\n\nOUTPUT=path_to_results\n\n/n/holylfs05/LABS/hsph_bioinfo/Lab/shared_resources/nextflow/nextflow run nf-core/rnaseq\n  -r 3.14.0 \\\n  -profile singularity \\\n  # next line is for passing pipeline parameters. can also insead use --params-file and use JSON downloaded from seqera\n  -c analysis.config \\\n  # next line is for optimizing resource requests, file does not yet exist for all pipelines\n  -c rnaseq.resources.config \\ \n  --outdir $OUTPUT\n  -c cannon.config \\\n  # next line optional, if you want to monitor your run in Seqera Platform\n  -with-tower\n  -resume\n</code></pre>"}]}